# Themes Game Word Quality Investigation

This directory contains the datascience investigation into word quality under different puzzle generation specifications.

## Structure

```text
themes_quality/
├── README.md                          # This file
├── notebooks/                         # Jupyter notebooks for analysis
│   ├── 01_baseline_analysis.ipynb    # Current system baseline
│   ├── 02_parameter_sweeps.ipynb     # Parameter variation analysis
│   ├── 03_quality_assessment.ipynb   # Word quality evaluation
│   └── 04_optimization.ipynb         # Parameter optimization
├── data/                              # Generated data and results
│   ├── raw/                          # Raw puzzle generation data
│   ├── processed/                    # Cleaned and processed data
│   └── results/                      # Analysis results and figures
├── scripts/                          # Analysis and data collection scripts
│   ├── generate_parameter_sweep.py   # Parameter sweep generation
│   ├── quality_assessment.py         # Quality evaluation tools
│   └── performance_analysis.py       # Performance monitoring
├── config/                           # Configuration files
│   └── investigation_config.json     # Investigation parameters
└── reports/                          # Generated reports and documentation
    └── findings/                     # Investigation findings
```text

## Quick Start

### Initial Setup

1. **Environment Setup**:
   ```bash
   cd scripts/datascience/themes_quality
   pip install -r requirements.txt
   ```

2. **DVC Setup** (one-time):
   ```bash
   # DVC is already initialized with GCS remote
   # To pull existing data:
   dvc pull
   ```

### Running Experiments

3. **Run Parameter Sweeps**:
   ```bash
   # Run the full DVC pipeline
   dvc repro
   
   # Or run specific stages
   dvc repro generate_parameter_sweep
   ```

4. **Start Investigation**:
   ```bash
   jupyter lab notebooks/run_full_investigation.ipynb
   ```

5. **Track Experiments**:
   ```bash
   # Run experiment with different parameters
   dvc exp run
   
   # Compare experiments
   dvc exp show
   ```

## MLOps Workflow with DVC

This investigation uses DVC (Data Version Control) for reproducible ML experiments:

### Data Management
- **Raw data**: Parameter sweep results stored in `data/raw/` (tracked by DVC)
- **Processed data**: Analysis results in `data/processed/` (generated by pipeline)
- **Remote storage**: All data backed up to GCS (`gs://aphorist-themes-quality-dvc`)

### Experiment Tracking
```bash
# Run experiment with custom parameters
dvc exp run -P parameter_sweeps.samples_per_configuration=5

# Compare different algorithm approaches
dvc exp run -P parameter_sweeps.algorithms='["N=K"]'
dvc exp run -P parameter_sweeps.algorithms='["N=K+D"]'

# View experiment results
dvc exp show --include-params parameter_sweeps.algorithms
```text

### Collaboration
```bash
# Get latest data and experiments
dvc pull
git pull

# Share your experiments
dvc push
git add . && git commit -m "Add new experiment results"
git push
```text

## Investigation Focus

- **Word Quality Analysis**: Distribution of word appropriateness across difficulty levels
- **Parameter Optimization**: Finding optimal frequency and similarity thresholds  
- **Algorithm Evaluation**: Comparing N=K vs alternative approaches
- **Performance Analysis**: Generation success rates and timing

## Key Metrics

- Word appropriateness scores (0-1 scale)
- Category coherence measures
- Generation success rates
- Performance benchmarks
- Quality control effectiveness

## DVC Pipeline Architecture

This project implements a modular NLP word categorization pipeline using DVC for reproducible machine learning workflows.

### Pipeline Overview

The DVC pipeline consists of multiple stages that process vocabulary data through various categorization algorithms:

1. **Vocabulary Generation**: Creates base vocabulary from source data
2. **Word Categorization**: Assigns semantic categories to words using NLP models
3. **Category Scoring**: Evaluates categorization quality and coherence
4. **Export Processing**: Generates final categorized vocabulary outputs

### Configuration

Pipeline behavior is controlled through configuration files:

- `params.yaml`: Main pipeline parameters and hyperparameters
- `config/pipeline_config.yaml`: Detailed categorization rules and thresholds
- `dvc.yaml`: Pipeline stage definitions and dependencies

### Parallel Processing

The pipeline is optimized for parallel processing with configurable worker counts (default: 6 workers) to efficiently handle large vocabulary datasets.

### Implementation Details

See `@temp_progress_plans/dvc_pipeline_setup.md` for detailed implementation steps and architecture decisions made during the DVC pipeline setup process.