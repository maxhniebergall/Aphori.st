# Enhanced Wiki Puzzle Generation Pipeline with Gemini Embeddings

puzzle_generation:
  total_puzzle_count: 80  # Configurable puzzle count  
  words_per_theme: 4  # 4 words per theme for 4x4 puzzles
  themes_per_puzzle: 4  # 4 themes per puzzle
  candidate_words_per_theme: 50  # Initial vector search candidates
  min_similarity_threshold: 0.3
  theme_selection_method: "random"
  random_seed: 42  # For reproducible puzzle generation

themes:
  source: "../data/categories/wiki_categories_filtered"
  exclude_categories: 
    - "General reference"
    - "Research" 
    - "Academic disciplines"
    - "Library science"
  min_theme_length: 3  # Minimum characters for theme name

vector_search:
  data_source: "../../themes_index"
  use_lemmatized: true
  similarity_metric: "cosine"
  max_search_candidates: 50

gemini:
  model_id: "gemini-embedding-001"  # Updated to latest Gemini model
  embedding_dimension: 3072  # Full dimension as originally planned
  api_key_env: "GEMINI_API_KEY"
  task_type: "SEMANTIC_SIMILARITY"
  
  # Rate limiting configuration optimized for 8 workers
  # Based on Gemini API limits: Free tier = 100 RPM, Tier 1 = 3000 RPM, Tier 2 = 5000 RPM, Tier 3 = 10000 RPM
  requests_per_minute: 2880  # Slightly more conservative for 8 workers (2880 RPM = 360 per worker max)
  min_request_interval: 0.05  # Reduced interval for faster processing with 8 workers (0.05s)
  retry_base_delay: 0.8  # Slightly faster retry for better throughput (0.8s)
  max_retries: 4  # Reduced retries to fail faster and redistribute work

paths:
  themes: "data/themes/"
  candidates: "data/candidates/"
  embeddings: "data/embeddings/"
  outputs: "data/outputs/"
  reports: "reports/"
  cache: "data/cache/"

output:
  format: "json"
  include_metadata: true
  include_similarity_scores: true
  csv_precision: 6  # Decimal places for embedding values
  
  # Two CSV outputs
  embedding_cache_file: "data/cache/all_embeddings.csv"  # All generated embeddings
  puzzle_embeddings_file: "data/embeddings/puzzle_embeddings.csv"  # Final puzzle words only

multiprocessing:
  enabled: true  # Enable/disable multiprocessing (set to false to use original sequential processing)
  worker_count: 8  # Number of worker processes (8 threads for optimal performance)
  task_queue_size: 160  # Maximum tasks in queue (20 per worker)
  result_queue_size: 160  # Maximum results in queue (20 per worker)
  max_concurrent_requests: 12  # Maximum concurrent API requests across all workers (1.5 per worker)
  cache_sync_interval: 45  # Seconds between cache syncs to disk (more frequent with more workers)

logging:
  level: "INFO"
  detailed_output: true
  log_embedding_stats: true